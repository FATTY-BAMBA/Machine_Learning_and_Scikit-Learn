{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b54e208",
   "metadata": {},
   "source": [
    "\n",
    "Several ML models are trained on subsets of the available input data and they are evalauted on complementary subset of the data. When performing supervise machine learning, a portion of the dataset is usually hold out as testing data. The testing data is not included in the training and it can be use to evaluate the generalization performance of the model. \n",
    "\n",
    "Herein, we demonstrate how common methods such as using train_test_split() class can mislead the model performance when it comes to the imbalance classification task. To tackle this issue, we implement Stratified K fold cross-validation, which splits the in K folds by preserving the class ratio as in the original dataset, for the new stratified dataset we have trained our classifier. The iris dataset is herein used to fit a support vector machine on it. In addition K-Fold and Stratified K-Fold cross validation techniques are also implemented to ascertain the generalization ability of the trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed7f43",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f336d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af190973",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5986680",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2112c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1032d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1f703",
   "metadata": {},
   "source": [
    "## Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e20c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c41ca",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05d2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82d3615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8809d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f108b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e558c2",
   "metadata": {},
   "source": [
    "## Note !!\n",
    "During training, the dataset is split into train and test set by the train_test_split class of scikit-learn library and after training the model, we get some accuracy in return. But is this the best accuracy of the model or whether this model will give the best performance at the time of deployment? Here comes the importance of cross validation splitting techniques. Cross validation is a technique that is use to detect overfitting, i.e. the model failing to generalize patttern effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0c047",
   "metadata": {},
   "source": [
    "## Cross_Validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61541af7",
   "metadata": {},
   "source": [
    "## K-fold CV\n",
    "The most commonly used validation technique is K-Fold CV. It involves splitting the training set into k numbers of folds. The first k-1 folds are used for training, and the remaining fold is held for testing, this process is repeated for K-folds. A  total of k folds are fitted and evaluated, and the score for each of this folds is returned. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cb6f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ddb35c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 1.        , 1.        ,\n",
       "       0.93333333, 0.93333333, 0.93333333, 1.        , 1.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, X, Y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1f0007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.97 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ea58d",
   "metadata": {},
   "source": [
    "## Stratified K-Fold\n",
    "K-Fold CV has shown encouraging results for balanced classification tasks. However, it fails for imbalance datasets. This is becasue K-Fold splits the data randomly without taking care of class imbalance. To overcome this, the stratified k fold cross-validation which is an extension of the K-Fold CV is used. Instead of splitting the data randomly, it splits the data in stratified manner. It maintains the same class ratio throughout the K folds as the ratio in the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fcfa89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "model_skf = svm.SVC()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "accuracy =[]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=None)\n",
    "skf.get_n_splits(X, Y)\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    X1_train, X1_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y1_train, Y1_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model_skf.fit(X1_train, Y1_train)\n",
    "    scores1 = model_skf.score(X1_test, Y1_test)\n",
    "    accuracy.append(scores1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6ad33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1041bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average_score: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "Average_score = sum(accuracy)/10\n",
    "print ('Average_score:', Average_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408f7aa",
   "metadata": {},
   "source": [
    "## \n",
    "As show above, we have a fairly robust model trained on 10 folds with a mean accuracy of 97.3% on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631774a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
